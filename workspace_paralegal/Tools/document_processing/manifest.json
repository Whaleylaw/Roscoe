{
  "category": "document_processing",
  "description": "PDF extraction and batch import tools for converting case documents to markdown format",
  "tools": [
    {
      "name": "read_pdf",
      "file": "read_pdf.py",
      "description": "Extract text and tables from PDFs to Markdown format using tiered OCR pipeline: PDFPlumber (text PDFs), PyTesseract (scanned PDFs), with future Google Cloud Document AI support. Auto-detects best method, provides quality metrics, and caches results to .md files for instant re-access.",
      "usage": "python /Tools/document_processing/read_pdf.py <pdf_path> [output_path] [--output-format markdown|text|json] [--no-cache] [--force-ocr] [--quality-report]",
      "examples": [
        "python /Tools/document_processing/read_pdf.py /case/medical_records/report.pdf",
        "python /Tools/document_processing/read_pdf.py /case/records/scan.pdf --no-cache",
        "python /Tools/document_processing/read_pdf.py /case/records/labs.pdf --output-format text",
        "python /Tools/document_processing/read_pdf.py /case/records/doc.pdf --quality-report",
        "python /Tools/document_processing/read_pdf.py /case/records/report.pdf /Reports/report.md"
      ],
      "when_to_use": [
        "Process PDF once to markdown for instant agent access",
        "Extract text from modern electronic medical records (PDFPlumber)",
        "OCR scanned medical records and older documents (PyTesseract)",
        "Extract tables from lab results, medication lists, vitals (inline in markdown)",
        "Process discovery documents with mixed content",
        "Auto-detect whether document is text-based or scanned",
        "Get quality metrics to know if cloud processing is needed"
      ],
      "features": [
        "Tier 1: PDFPlumber for text-based PDFs (fast, accurate)",
        "Tier 2: PyTesseract OCR for scanned PDFs (handles images)",
        "Auto-detection of PDF type (text vs scanned)",
        "Markdown output with frontmatter metadata (quality scores, extraction method, timestamp)",
        "Tables embedded inline as markdown tables (not separate JSON)",
        "Quality metrics and confidence scoring",
        "Hybrid mode with automatic fallback",
        "Smart caching: checks for existing .md file and validates by timestamp",
        "Cache invalidation: re-processes if PDF newer than .md file"
      ],
      "flags": {
        "--output-format FMT": "Output format: markdown (default), text, or json",
        "--no-cache": "Force re-processing even if .md file exists",
        "--force-ocr": "Force OCR processing even if text is detected",
        "--extract-tables": "Save tables to separate JSON file (text format only, markdown includes inline)",
        "--quality-report": "Show detailed quality metrics",
        "--method METHOD": "Force specific method (pdfplumber|ocr|auto)",
        "--ocr-dpi DPI": "OCR resolution (default: 300)"
      },
      "dependencies": [
        "pdfplumber (install: pip install pdfplumber)",
        "pytesseract (install: pip install pytesseract)",
        "pdf2image (install: pip install pdf2image)",
        "tesseract binary (install: brew install tesseract on macOS)"
      ]
    },
    {
      "name": "import_documents",
      "file": "import_documents.py",
      "description": "Batch import all PDFs in a case folder to markdown format. Pre-processes all documents once so agents can read .md files instantly instead of re-processing PDFs every time. Creates processing logs and quality reports.",
      "usage": "python /Tools/document_processing/import_documents.py <case_folder> [--force] [--quality-threshold N] [--report-dir DIR]",
      "examples": [
        "python /Tools/document_processing/import_documents.py /mo_alif",
        "python /Tools/document_processing/import_documents.py /mo_alif --force",
        "python /Tools/document_processing/import_documents.py /mo_alif --quality-threshold 70",
        "python /Tools/document_processing/import_documents.py /mo_alif --report-dir /custom_reports"
      ],
      "when_to_use": [
        "Initial case setup - import all documents at once",
        "Pre-process entire case folder for fast agent access",
        "Batch convert all PDFs to markdown",
        "Get quality assessment of all case documents",
        "Identify low-quality documents needing review or cloud processing",
        "Periodic re-import when new documents added to case"
      ],
      "features": [
        "Recursive PDF discovery (finds all PDFs in case folder and subfolders)",
        "Batch processing with progress tracking",
        "Smart caching: skips PDFs that already have .md files (unless --force)",
        "Quality tracking and flagging (documents below threshold marked for review)",
        "Two-format reporting: JSON log + Markdown index",
        "Error handling: continues processing if individual PDFs fail",
        "Processing statistics: counts by method (PDFPlumber vs OCR), quality levels"
      ],
      "flags": {
        "--force": "Re-process all PDFs even if .md files already exist",
        "--quality-threshold N": "Flag documents with quality score below N (default: 60)",
        "--report-dir DIR": "Custom directory for reports (default: /Reports)"
      },
      "workflow": {
        "step_1": "Find all PDFs in case folder recursively",
        "step_2": "Process each PDF to markdown using read_pdf.py (with caching)",
        "step_3": "Track results: quality scores, methods used, errors",
        "step_4": "Generate import_log.json with all processing metadata",
        "step_5": "Generate DOCUMENT_INDEX.md organized by folder with quality breakdown",
        "step_6": "Report summary: total processed, quality distribution, files needing review"
      },
      "output_files": {
        "per_pdf": "<pdf_name>.md (same directory as PDF)",
        "reports": [
          "/Reports/import_log.json - Complete processing log with metadata",
          "/Reports/DOCUMENT_INDEX.md - Human-readable index organized by folder"
        ]
      },
      "dependencies": [
        "Requires read_pdf.py and all its dependencies",
        "pdfplumber, pytesseract, pdf2image, tesseract binary"
      ]
    }
  ],
  "performance": {
    "text_pdfs": "~1-2 seconds per document (PDFPlumber)",
    "scanned_pdfs": "~5-10 seconds per document (OCR)",
    "incremental": "Only processes new PDFs (skips existing .md files)"
  },
  "token_savings": "Massive - agents read .md files instantly vs re-processing PDFs every time (saves 5-10 seconds + 800-2000 tokens per document access)",
  "cost": "FREE (uses local OCR tiers)"
}
